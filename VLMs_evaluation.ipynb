{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",

  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ziijiecheng/VLM_robustness/blob/main/VLMs_evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install required packages"
      ],
      "metadata": {
        "id": "BsvvpR9vO9QL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch pillow openai anthropic open_clip_torch transformers requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqH64voDPDFm",
        "outputId": "a8aa7657-8681-4546-ff19-147d2144305f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.82.1)\n",
            "Collecting anthropic\n",
            "  Downloading anthropic-0.52.2-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting open_clip_torch\n",
            "  Downloading open_clip_torch-2.32.0-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (0.21.0+cu124)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (2024.11.6)\n",
            "Collecting ftfy (from open_clip_torch)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (0.32.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (0.5.3)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (1.0.15)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->open_clip_torch) (1.1.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->open_clip_torch) (0.2.13)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m129.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m97.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m109.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading anthropic-0.52.2-py3-none-any.whl (286 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.3/286.3 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading open_clip_torch-2.32.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ftfy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, anthropic, open_clip_torch\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed anthropic-0.52.2 ftfy-6.3.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 open_clip_torch-2.32.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "import torch\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import time\n",
        "\n",
        "# Import model-specific libraries\n",
        "from openai import OpenAI\n",
        "import anthropic\n",
        "from open_clip import create_model_from_pretrained, get_tokenizer\n",
        "from transformers import AutoModel, AutoTokenizer, MllamaForConditionalGeneration, AutoProcessor, AutoModelForImageTextToText"
      ],
      "metadata": {
        "id": "hBbx-NQGPQAa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_image(image_path):\n",
        "    \"\"\"Encode the image to a base64 string.\"\"\"\n",
        "    with open(image_path, \"rb\") as image_file:\n",
        "        return base64.b64encode(image_file.read()).decode(\"utf-8\")"
      ],
      "metadata": {
        "id": "nGLFoCftxQ2y"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL FUNCTIONS"
      ],
      "metadata": {
        "id": "9bvW1IzvPogI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#GPT\n",
        "def evaluate_image_chatgpt(client, model, image_path, role, content, max_retries=2):\n",
        "    \"\"\"Evaluate the image using ChatGPT with retry logic.\"\"\"\n",
        "    base64_image = encode_image(image_path)\n",
        "\n",
        "    for attempt in range(max_retries + 1):\n",
        "        try:\n",
        "            response = client.chat.completions.create(\n",
        "                model=model,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": role},\n",
        "                    {\"role\": \"user\", \"content\": [\n",
        "                        {\"type\": \"text\", \"text\": content},\n",
        "                        {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{base64_image}\"}}\n",
        "                    ]}\n",
        "                ],\n",
        "                temperature=0.0,\n",
        "            )\n",
        "            return response.choices[0].message.content\n",
        "        except Exception as e:\n",
        "            if attempt < max_retries:\n",
        "                print(f\"Error occurred with ChatGPT: {e}. Retrying... (Attempt {attempt + 1} of {max_retries})\")\n",
        "                time.sleep(2)  # Wait for 2 seconds before retrying\n",
        "            else:\n",
        "                raise Exception(f\"Failed to evaluate image with ChatGPT after {max_retries + 1} attempts: {image_path}\")"
      ],
      "metadata": {
        "id": "vN1QfEAWPrZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Claude\n",
        "def evaluate_image_claude(client, model, image_path, role, content, max_retries=2):\n",
        "    \"\"\"Evaluate the image using Claude with retry logic.\"\"\"\n",
        "    with open(image_path, \"rb\") as image_file:\n",
        "        base64_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
        "\n",
        "    for attempt in range(max_retries + 1):\n",
        "        try:\n",
        "            message = client.messages.create(\n",
        "                model=model,\n",
        "                max_tokens=1024,\n",
        "                temperature=0,\n",
        "                system=role,\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": [\n",
        "                            {\n",
        "                                \"type\": \"image\",\n",
        "                                \"source\": {\n",
        "                                    \"type\": \"base64\",\n",
        "                                    \"media_type\": \"image/png\",\n",
        "                                    \"data\": base64_image,\n",
        "                                },\n",
        "                            },\n",
        "                            {\"type\": \"text\", \"text\": content},\n",
        "                        ],\n",
        "                    }\n",
        "                ],\n",
        "            )\n",
        "            return message.content[0].text\n",
        "        except Exception as e:\n",
        "            if attempt < max_retries:\n",
        "                print(f\"Error occurred with Claude: {e}. Retrying... (Attempt {attempt + 1} of {max_retries})\")\n",
        "                time.sleep(2)  # Wait for 2 seconds before retrying\n",
        "            else:\n",
        "                raise Exception(f\"Failed to evaluate image with Claude after {max_retries + 1} attempts: {image_path}\")"
      ],
      "metadata": {
        "id": "h6xvNyfdP60g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#BiomedCLIP\n",
        "def evaluate_image_biomedclip(preprocess, model, tokenizer, image_path, labels, device, context_length=256):\n",
        "    \"\"\"Evaluate the image using BiomedCLIP.\"\"\"\n",
        "    template = 'the diagnosis of this Optical Coherence Tomography is:'\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = preprocess(image).unsqueeze(0).to(device)\n",
        "\n",
        "    texts = tokenizer([template + l for l in labels], context_length=context_length).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        image_features, text_features, logit_scale = model(image, texts)\n",
        "        logits = (logit_scale * image_features @ text_features.t()).softmax(dim=-1)\n",
        "\n",
        "    prediction_index = logits.argmax().item()\n",
        "    return labels[prediction_index]"
      ],
      "metadata": {
        "id": "iGH5JFlgQE5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Llama\n",
        "def evaluate_image_llama(model, processor, image_path, content, device, max_retries=2):\n",
        "    \"\"\"Evaluate the image using Llama with retry logic.\"\"\"\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": [\n",
        "            {\"type\": \"image\"},\n",
        "            {\"type\": \"text\", \"text\": content}\n",
        "        ]}\n",
        "    ]\n",
        "    input_text = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
        "\n",
        "    for attempt in range(max_retries + 1):\n",
        "        try:\n",
        "            inputs = processor(\n",
        "                image,\n",
        "                input_text,\n",
        "                add_special_tokens=False,\n",
        "                return_tensors=\"pt\"\n",
        "            ).to(device)\n",
        "            output = model.generate(**inputs, max_new_tokens=800)\n",
        "            return processor.decode(output[0])\n",
        "        except Exception as e:\n",
        "            if attempt < max_retries:\n",
        "                print(f\"Error occurred with Llama: {e}. Retrying... (Attempt {attempt + 1} of {max_retries})\")\n",
        "                time.sleep(2)  # Wait for 2 seconds before retrying\n",
        "            else:\n",
        "                raise Exception(f\"Failed to evaluate image with Llama after {max_retries + 1} attempts: {image_path}\")"
      ],
      "metadata": {
        "id": "XpKeVyBSQd28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Med Gemma\n",
        "def evaluate_image_medgemma(model, processor, image_path, content, device, max_retries=2):\n",
        "    \"\"\"Evaluate the image using MedGemma-4B-IT model with retry logic.\"\"\"\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": \"You are an expert radiologist.\"}]},\n",
        "        {\"role\": \"user\", \"content\": [\n",
        "            {\"type\": \"text\", \"text\": content},\n",
        "            {\"type\": \"image\", \"image\": image}\n",
        "        ]}\n",
        "    ]\n",
        "    inputs = processor.apply_chat_template(\n",
        "        messages, add_generation_prompt=True, tokenize=True,\n",
        "        return_dict=True, return_tensors=\"pt\"\n",
        "    ).to(device, dtype=torch.bfloat16)\n",
        "    model.eval()\n",
        "\n",
        "    input_len = inputs[\"input_ids\"].shape[-1]\n",
        "\n",
        "    for attempt in range(max_retries + 1):\n",
        "        try:\n",
        "            with torch.inference_mode():\n",
        "                generation = model.generate(**inputs, max_new_tokens=1500, do_sample=False)\n",
        "                generation = generation[0][input_len:]\n",
        "\n",
        "            decoded = processor.decode(generation, skip_special_tokens=True)\n",
        "            return decoded\n",
        "        except Exception as e:\n",
        "            if attempt < max_retries:\n",
        "                print(f\"Error occurred with MedGemma: {e}. Retrying... (Attempt {attempt + 1} of {max_retries})\")\n",
        "                time.sleep(2)\n",
        "            else:\n",
        "                raise Exception(f\"Failed to evaluate image with MedGemma after {max_retries + 1} attempts: {image_path}\")\n"
      ],
      "metadata": {
        "id": "tEmb0UyyHsL4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CONFIGURATION"
      ],
      "metadata": {
        "id": "Ukqwt4VrnWCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image_from_url(image_url, save_path='temp_image.png'):\n",
        "    # Send GET request to fetch the image content\n",
        "    response = requests.get(image_url)\n",
        "\n",
        "    # Open the image from the response content\n",
        "    image = Image.open(BytesIO(response.content)).convert('L')\n",
        "\n",
        "    # Save the image locally so we can pass the path to apply_augmentations\n",
        "    image.save(save_path)\n",
        "    return save_path\n",
        "\n",
        "# 1. Set your Google Drive file ID (shareable link)\n",
        "img_url = 'https://drive.google.com/uc?export=view&id=1pmrnvXwMxgC8fpZ-sz9DJfkSHRYUkSCO'  # Replace with your actual file ID\n",
        "image_path = load_image_from_url(img_url)\n",
        "print(f\"Downloaded image: {image_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ky2MgAvdqu7w",
        "outputId": "09804fa0-0ba9-4a16-8648-2ba44f68d116"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded image: temp_image.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "run GPT-4o"
      ],
      "metadata": {
        "id": "6jNyAVPQvTkh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(api_key='#use your own key')\n",
        "model = 'gpt-4o-2024-08-06'\n",
        "role = 'Medical knowledge educator'\n",
        "content = \"How can we identify the features of choroidal neovascularization, Diabetic macular edema and early AMD in a Optical Coherence Tomography image of a person? Imagine you are an educator tasked with helping a student identify the features of an OCT image and whether or not the image shows signs of these retinal diseases as described by those features. As an educator, conclude your answer in - 'retinal diseases' or 'normal'. Describe your reasoning in steps.\"\n",
        "prediction = evaluate_image_chatgpt(client, model, image_path, role, content)\n",
        "print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sa67MWCtvS29",
        "outputId": "be13cc02-db14-44e7-b07d-c52f8b190f5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To identify features of choroidal neovascularization (CNV), diabetic macular edema (DME), and early age-related macular degeneration (AMD) in an Optical Coherence Tomography (OCT) image, follow these steps:\n",
            "\n",
            "1. **Choroidal Neovascularization (CNV):**\n",
            "   - **Look for:** Subretinal or intraretinal fluid, and hyperreflective material beneath the retina.\n",
            "   - **In the image:** Check for any abnormal blood vessels or fluid accumulation beneath the retinal layers.\n",
            "\n",
            "2. **Diabetic Macular Edema (DME):**\n",
            "   - **Look for:** Thickening of the retina and cystoid spaces within the retina.\n",
            "   - **In the image:** Identify any areas where the retina appears swollen or has cyst-like spaces.\n",
            "\n",
            "3. **Early Age-related Macular Degeneration (AMD):**\n",
            "   - **Look for:** Drusen, which are small, yellowish deposits beneath the retina.\n",
            "   - **In the image:** Check for any small, round, hyperreflective spots beneath the retinal pigment epithelium.\n",
            "\n",
            "**Analysis of the Image:**\n",
            "- The image shows significant cystoid spaces within the retina, indicating fluid accumulation.\n",
            "- There is also a noticeable thickening of the retina.\n",
            "\n",
            "**Conclusion:**\n",
            "Based on the presence of cystoid spaces and retinal thickening, the features are consistent with diabetic macular edema (DME). Therefore, the image indicates signs of retinal diseases.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "run Claude 3.5 Sonnet 2024.6.20"
      ],
      "metadata": {
        "id": "v-WUho0kNYKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = anthropic.Anthropic(api_key='#use your own key')\n",
        "model = 'claude-3-5-sonnet-20240620'\n",
        "role = 'Medical knowledge educator'\n",
        "content = \"How can we identify the features of choroidal neovascularization, Diabetic macular edema and early AMD in a Optical Coherence Tomography image of a person? Imagine you are an educator tasked with helping a student identify the features of an OCT image and whether or not the image shows signs of these retinal diseases as described by those features. As an educator, conclude your answer in - 'retinal diseases' or 'normal'. Describe your reasoning in steps.\"\n",
        "prediction = evaluate_image_claude(client, model, image_path, role, content)\n",
        "print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sw3YN1kHNps4",
        "outputId": "b615e3f4-b3c1-451c-be24-e1e5dfc0d2bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "As an educator helping a student identify features in an OCT image, I would guide them through the following steps:\n",
            "\n",
            "1. Orientation: This is an OCT image of the retina. The top of the image represents the inner retinal layers, while the bottom shows the choroid and sclera.\n",
            "\n",
            "2. Normal retinal anatomy: Look for clearly defined retinal layers, a smooth retinal contour, and a uniform choroidal layer.\n",
            "\n",
            "3. Choroidal Neovascularization (CNV) features:\n",
            "   - Look for irregular elevations of the retinal pigment epithelium (RPE)\n",
            "   - Check for hyper-reflective material above or below the RPE\n",
            "   - Observe for any disruption of the normal retinal architecture\n",
            "\n",
            "4. Diabetic Macular Edema (DME) features:\n",
            "   - Look for retinal thickening, especially in the central macula\n",
            "   - Check for intraretinal cystoid spaces (dark, fluid-filled areas)\n",
            "   - Observe for loss of the normal foveal contour\n",
            "\n",
            "5. Early Age-related Macular Degeneration (AMD) features:\n",
            "   - Look for drusen (small bumps) at the level of the RPE\n",
            "   - Check for subtle RPE irregularities or thickening\n",
            "   - Observe for any mild distortion of the overlying retinal layers\n",
            "\n",
            "In this particular OCT image:\n",
            "- The retinal layers appear well-defined and organized\n",
            "- There is no obvious retinal thickening or fluid accumulation\n",
            "- The RPE layer seems smooth without significant irregularities or elevations\n",
            "- There are no visible drusen or signs of choroidal neovascularization\n",
            "\n",
            "Based on these observations, this OCT image appears to show a normal retinal structure without clear signs of CNV, DME, or early AMD.\n",
            "\n",
            "Conclusion: normal\n",
            "\n",
            "Remember, while this image appears normal, it's always important to correlate OCT findings with clinical examination and other diagnostic tests for a comprehensive assessment.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "run Claude 3.5 Sonnet 2024.10.22"
      ],
      "metadata": {
        "id": "SkK30BpXQSEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = anthropic.Anthropic(api_key='#use your own key')\n",
        "model = 'claude-3-5-sonnet-20241022'\n",
        "role = 'Medical knowledge educator'\n",
        "content = \"How can we identify the features of choroidal neovascularization, Diabetic macular edema and early AMD in a Optical Coherence Tomography image of a person? Imagine you are an educator tasked with helping a student identify the features of an OCT image and whether or not the image shows signs of these retinal diseases as described by those features. As an educator, conclude your answer in - 'retinal diseases' or 'normal'. Describe your reasoning in steps.\"\n",
        "prediction = evaluate_image_claude(client, model, image_path, role, content)\n",
        "print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejAvvoyPQULM",
        "outputId": "10672622-342f-4092-bc85-f2e9b32e9233"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let me help you analyze this OCT image as an educator:\n",
            "\n",
            "Step 1 - Basic OCT Interpretation:\n",
            "- This is a cross-sectional image of the retina showing distinct layers\n",
            "- The retinal layers appear relatively well-organized\n",
            "- The retinal pigment epithelium (RPE) layer appears as a bright continuous line\n",
            "\n",
            "Step 2 - Looking for CNV features:\n",
            "- CNV would show fluid accumulation above or below RPE\n",
            "- Would see irregular RPE elevation or disruption\n",
            "- No obvious signs of subretinal or sub-RPE fluid\n",
            "- No obvious neovascular membranes visible\n",
            "\n",
            "Step 3 - Checking for DME indicators:\n",
            "- DME shows retinal thickening and cystoid spaces\n",
            "- Would see dark fluid-filled spaces within retinal layers\n",
            "- This image shows normal retinal thickness\n",
            "- No obvious intraretinal fluid collections\n",
            "\n",
            "Step 4 - Early AMD signs:\n",
            "- Would look for drusen (RPE bumps/elevations)\n",
            "- Check for RPE irregularities or disruption\n",
            "- Look for any hyper-reflective material\n",
            "- The RPE layer appears relatively smooth and continuous\n",
            "- No obvious drusen visible\n",
            "\n",
            "Step 5 - Overall Assessment:\n",
            "- Retinal layers maintain normal architecture\n",
            "- No significant fluid accumulation\n",
            "- RPE appears intact without obvious disruption\n",
            "- Normal retinal thickness\n",
            "- No characteristic features of CNV, DME or early AMD\n",
            "\n",
            "Conclusion: NORMAL\n",
            "Reasoning: The image shows well-preserved retinal architecture without the characteristic features of choroidal neovascularization (no fluid accumulation or RPE disruption), diabetic macular edema (no retinal thickening or cystoid spaces), or early AMD (no drusen or RPE irregularities). The retinal layers appear organized with normal thickness and a continuous RPE layer.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "run biomedCLIP"
      ],
      "metadata": {
        "id": "P-qMlhm8Qqm6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [\"normal\", \"retinal diseases\"]\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model, preprocess = create_model_from_pretrained('hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224')\n",
        "tokenizer = get_tokenizer('hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224')\n",
        "model.to(device)\n",
        "model.eval()\n",
        "prediction = evaluate_image_biomedclip(preprocess, model, tokenizer, image_path, labels, device)\n",
        "print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZwC4Ry-Q669",
        "outputId": "23933e25-c83f-4378-fb3b-719d53f8afaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "retinal diseases\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "run llava 3.2 11b"
      ],
      "metadata": {
        "id": "Hiu43yWYRwVD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OprSkRA-ZNOb",
        "outputId": "c6afa3b3-f569-4bff-e379-07dd27bf815f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5Y_DwNBXJgI",
        "outputId": "691cd1b1-8f91-445a-b461-0b46093a1195"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: read).\n",
            "The token `VLM_eva` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `VLM_eva`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli download meta-llama/Llama-3.2-11B-Vision-Instruct \\\n",
        "  --include \"original/*\" \\\n",
        "  --local-dir Llama-3.2-11B-Vision-Instruct"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wZ52HeqZPp7",
        "outputId": "cb6e66c2-da6a-476c-cc08-88308ffc5697"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rFetching 3 files:   0% 0/3 [00:00<?, ?it/s]\rFetching 3 files: 100% 3/3 [00:00<00:00, 1616.30it/s]\n",
            "/content/Llama-3.2-11B-Vision-Instruct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "content = \"How can we identify the features of choroidal neovascularization, Diabetic macular edema and early AMD in a Optical Coherence Tomography image of a person? Imagine you are an educator tasked with helping a student identify the features of an OCT image and whether or not the image shows signs of these retinal diseases as described by those features. As an educator, conclude your answer in - 'retinal diseases' or 'normal'. Describe your reasoning in steps.\"\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = MllamaForConditionalGeneration.from_pretrained(\n",
        "    \"meta-llama/Llama-3.2-11B-Vision-Instruct\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "processor = AutoProcessor.from_pretrained(\"meta-llama/Llama-3.2-11B-Vision-Instruct\")\n",
        "prediction = evaluate_image_llama(model, processor, image_path, content, device)\n",
        "print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "bedf1e20c2774ebc88dd85e3e9f8559b",
            "87378c484af14cb99f5b91a6e0ef1c0b",
            "17251d1d515e4412a2b36873367b5222",
            "2c365dc1298243adb65b803d4b79102a",
            "0244b0f2bc92414c95f9e2386a45a247",
            "6293c5ad601947869849c1ee0abd78d9",
            "8177ecee2d1943538789b9758ed000f3",
            "a21046ddf50046ba85261011dc88809f",
            "0691076eebc14102912b137d014d31ca",
            "5fb1f2b9bfd14839a108a399e706f644",
            "37f9566b286e457190a755a62ff3153d",
            "12e0c979813b43e0815fe4cb315addef",
            "82545dccf5794901b07c71fdff6563be",
            "06437f32d379408e9ff62bf4c901aed5",
            "9a7100163f3b4a62a865fc5f38374266",
            "eee21567c3db4df7a16bf1d38a99d938",
            "a41e2023af7c441b8f6b15276f2c9bad",
            "ca34fba86a344810ac337ae9e11ff7f5",
            "81c38014fdb141989a32bbf22e449754",
            "d29d2dc8506c4e499f542aca8b00b267",
            "221b80578e4944b685757e1dc6469253",
            "f61b527c1fb34d538d5473f7719fd6a7",
            "c26b72b3f9bd47968314b11f463b2444",
            "f7118f95ed284e41968db62f53241469",
            "c48d3345dbf4442f99099ad1c3380182",
            "edb2a6aea86e49e289352656e578dd4a",
            "bb2cea9802a84eaebb1e287535687148",
            "f3b3be65de3345e185b005006628ddfe",
            "864f88e8e1c84ec4bddbfa08576b3322",
            "4893647e4cf141468fde453841091b8f",
            "89d153dcb2ff4d128268aab1316b64d6",
            "7a3d0cb8b2944d7c84b2e03772ba8f2d",
            "566cb64c4fb24cdd933bb3cfa6c17c78",
            "bb521958015443deac389e13384531e9",
            "68134d01958049c5b6e9e6bddc8c292b",
            "36ea45f3012044928145ce76566600e2",
            "ff315cc07a334aa8bab7c4778138e3f0",
            "7ae7285b2aae4cd385396987969794b8",
            "37c1b3946b444e4eb6cf5dccce58139c",
            "7875ee2c17a84102937a3d205540c9df",
            "b11a50303b6246b9a0c06c89e127ee84",
            "c6d247aca39648adbc248c773f9a1c1a",
            "55677cff654b472199bc894b8bc69430",
            "e0c4a18f4c6e488ea61107c901d302b4",
            "93a684af0cfe4718bb4ae08ef1680ee9",
            "f2b1dc89dda74241aa3108474664f358",
            "b3d82f4b696b4aeaabf897db75247bad",
            "2a2b6d35851549469be68f5acfe8b8e6",
            "d19e825d834a4b28a272a7f54b0c94cd",
            "0230148176fa4d148c4429912a5272d7",
            "7c7bf62779044fc8a2a1e50858418cc4",
            "64e299fdae6e4513a1b450e905bf934d",
            "1e32d343068842639d988102fca426f9",
            "d7f63e37527749f7a02b6d2df64b5762",
            "80be87fefe96403192cb609ae7c5ce6e",
            "2b1f9c078e804611ac8443ec07d54f87",
            "077dc79d389d411c97144245f0dab96e",
            "0325f9fad346468781d7300af3d84f4e",
            "e25f63d2b7134ad19d353fdb04b37b44",
            "a9a02c3e612b460e978b3d78c4e7dbc7",
            "13e0e849e0b84ced9bc664da671ac116",
            "81c2e51bf2e94f56b3b5669d94e32039",
            "b58bd65df440458dbf30bcb07bfa6982",
            "b08c14ef8b3845f88c0cbe20af4ab1de",
            "9b188d686e644b41aa50097ca12e8d56",
            "eb8b2b7256934a4a9dcbefbd775f4455",
            "b0ba4b2592804200bf25c72705ad0e36",
            "57485ee992f44dfa8475095d5c764363",
            "a18f3f9b5ba54c9997eacba06db2032d",
            "30517d94f1a844adaa25db0f4b5bf1db",
            "3ed4f4986ea64621b78b42f66752f81a",
            "829f0cff11cc48ea8f877630f2dbf814",
            "468b3e86585b4683b6581b5c9538944d",
            "1ece3ff89562498e83115c05fe7c1aa1",
            "f06f412501a1409f8c060ab848c56d42",
            "26ffbbd8424b4b73ac05f649c366ecd8",
            "3198ae7a520a4ad6b9daac075279220c",
            "85664e8856c3402caf436645118fe7d8",
            "31498aa275184f8794c25f5a82fa87d7",
            "2836ebfcaa344c809315cc29c82567e3",
            "86416e9148974ff4a9f9572b2043a481",
            "b7c4216f6c9545b8a2897ae47a02eed9",
            "62c3f776d0934071983c36c435e252aa",
            "aaa7254057e848eda50e61b0c0f7cac5",
            "5e6fbf9b99944db0890c03f319bbd3d7",
            "3ea1952c8f97445a881b3a2a1ff820f3",
            "eda52c3dce0b435b9447a79d74774782",
            "d13cb8c589f84cfba54cd68d26fb241f",
            "efef56f9c71b407f8ae1329ec0b423f7",
            "71b4d864398c4c16a0d59141a9b0731d",
            "cd19ff7d973445f5a8680164d06c936b",
            "4c2b79ff2c76499ba2fcdd9343946701",
            "cd4110f861b04f808feaa581e5dff3dd",
            "140d4a902fbf4041922f2253031b03ee",
            "6df0ab743ae649d6ac647fbef70ac6f6",
            "81fc9b88a4d34c56a862f64c8069c134",
            "1a5a530b556f48c6a83a071244283887",
            "113cfd735a444498a29eed49fa5a4d37",
            "88ce781b48804c80987d581143b044d0",
            "5a087445c7e548e0a75dcd0afc185358",
            "6423a48c706644aba81a356df4ae119a",
            "8e2b4223f8fb4fd8ac57e2f3b65de5a1",
            "c0fa5502f04f47e59cb9f6f7337989b7",
            "10daf8039a564378beae88a2a138729c",
            "2693f11ef22249dcab8c8966f7730136",
            "d7dd1fb90566474ca03ec7a2d590c070",
            "ecfb6a3845ca4594bd54bedee85ed29a",
            "7b9b87dfedb646e2a87e07b112f00019",
            "fae02c6ebdf742d7a1ed03b26cf382fc",
            "bc64dc78d1284422bb7ab63e50ea8ab8",
            "2cad8de8c7ef4dfcad750579d0d99c98",
            "317d9321a599491c9539981dcd68735d",
            "8d224f3efbdc4045a4f704a31895262f",
            "5ea733274b0442368273902533dc2585",
            "7b9abf6e6acf4695bf6775190d34e706",
            "4a90dbde76164de0856e9f2df9bb92ba",
            "253e1e07cab94b3db18a071997bd7277",
            "37bfc7c2f257425fa57462861f034ae9",
            "9277ea896978495ebb64a48c8244fe14",
            "491cc43981114ce1841aaafe30b5407c",
            "99adefcf13064619bb0e3098a53cd732",
            "3d947a811ad146de997595126f359870",
            "c2b0144b20fc4d4fa4ed04253b077165",
            "ef2289c26c074cef82cbe35177071719",
            "01e9fc4c133b4a88a56714775b696d86",
            "60e1d8aad8dc49fa84a460a9235bd31b",
            "93bce40173424958bb38015a6fbbd694",
            "344a5195d557499caf5fae616d0bf8f7",
            "f34ad0ecbb364c6f800423e2b5329620",
            "0fd7c2fa5c9a46c197e345bbf1be49e2",
            "d5baf57f365b4e6e85decc0d88f152bf",
            "db55ed8e070b4d559c7c84e26b2f8163",
            "0651238c3ea34edb9e0bf34df0cadd45",
            "64af3178eadd454980124712ad36930a",
            "d2d673baad3949be8db8b8725a976557",
            "728c394037274979ba502e8854cb2864",
            "02204101ef2a495185100601395c2f7b",
            "9b0149d8b7534098948e58ef5e69686f",
            "29be4cdd584244d3b1ec90937d7c9bf7",
            "b6a51a531dbd4fbf8a07041ed4a87659",
            "f4f8036567e24a43ad24e68842cb6291",
            "d50a2268317a4ae1a8032ab00b0b9639",
            "48a79367195b4adfb22e7bcc1653e73d",
            "dfb3506e56bb4513a78cd7cc311ac9ae",
            "aa778abfad51486799fca3a5c6bdc0a7",
            "9a26bbc2087649c2834bf6355e0ca3ad",
            "b4e23db987524f0c90924d4d34926ec8",
            "d2012834824244719c757f3fbdb61305",
            "3fa82a0361b448b395cf68717445ae79",
            "c2b0d7cc07f64b2f850845e290147ade",
            "2132da6e2b8c4c11bfb04a2a607dc22b",
            "183a526e3ed246b29762d430b62774b0",
            "362118b4372444819b7c39b990f547fe",
            "06e95688661041b6b8da9b5f2d2632e3",
            "c860f8d7b1a84d02b0ff84c451107ed9",
            "7903cd41b5d940e2ba8a67a2e92aabad",
            "8145dc24d97847c79f74308bd9ae63c8",
            "c772fd72d43a4fd9a3ce49cb8663bcd6",
            "da6ce12dc5664861b338960afa4c54d8",
            "c0f133e003414f01a8fe7090f1d2084c",
            "4f8ea2d8397346bca51b1044cd650853",
            "f54a072abfe641848f97b82b9119c5cd",
            "8acb1056eea14163afedbb19494c2531",
            "1202b485bad849e9b468ef3455622be3",
            "8d9d2eab09414e6d833bcb21839f3883"
          ]
        },
        "id": "QFBndhApR0Hr",
        "outputId": "fddb3a9d-ee3b-40a6-a33f-c9884e32a4a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bedf1e20c2774ebc88dd85e3e9f8559b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/5.07k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "12e0c979813b43e0815fe4cb315addef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/89.4k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c26b72b3f9bd47968314b11f463b2444",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading shards:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb521958015443deac389e13384531e9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00005.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "93a684af0cfe4718bb4ae08ef1680ee9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00005.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b1f9c078e804611ac8443ec07d54f87",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00003-of-00005.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b0ba4b2592804200bf25c72705ad0e36",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00004-of-00005.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "85664e8856c3402caf436645118fe7d8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00005-of-00005.safetensors:   0%|          | 0.00/1.47G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:accelerate.utils.modeling:The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "efef56f9c71b407f8ae1329ec0b423f7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a087445c7e548e0a75dcd0afc185358",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/215 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2cad8de8c7ef4dfcad750579d0d99c98",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/437 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3d947a811ad146de997595126f359870",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/55.8k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0651238c3ea34edb9e0bf34df0cadd45",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dfb3506e56bb4513a78cd7cc311ac9ae",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/454 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c860f8d7b1a84d02b0ff84c451107ed9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "chat_template.json:   0%|          | 0.00/5.09k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "<|image|>How can we identify the features of choroidal neovascularization, Diabetic macular edema and early AMD in a Optical Coherence Tomography image of a person? Imagine you are an educator tasked with helping a student identify the features of an OCT image and whether or not the image shows signs of these retinal diseases as described by those features. As an educator, conclude your answer in -'retinal diseases' or 'normal'. Describe your reasoning in steps.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "**Step 1: Identify the features of choroidal neovascularization (CNV) in an OCT image.**\n",
            "\n",
            "*   CNV is characterized by the presence of new blood vessels growing under the retina.\n",
            "*   In an OCT image, CNV appears as a hyperreflective lesion with a characteristic \"flower petal\" or \"leaf-like\" pattern.\n",
            "*   The lesion may also show a hyperreflective border and a hyporeflective center.\n",
            "\n",
            "**Step 2: Identify the features of diabetic macular edema (DME) in an OCT image.**\n",
            "\n",
            "*   DME is characterized by the accumulation of fluid in the macula, leading to retinal thickening.\n",
            "*   In an OCT image, DME appears as a hyperreflective area with cystoid spaces or a diffuse increase in retinal thickness.\n",
            "*   The foveal contour may be disrupted, and there may be an increase in retinal pigment epithelium (RPE) thickness.\n",
            "\n",
            "**Step 3: Identify the features of early age-related macular degeneration (AMD) in an OCT image.**\n",
            "\n",
            "*   Early AMD is characterized by the presence of drusen, which are small yellow deposits under the retina.\n",
            "*   In an OCT image, drusen appear as hyperreflective spots or patches in the RPE layer.\n",
            "*   There may also be an increase in RPE thickness and a loss of photoreceptors.\n",
            "\n",
            "**Step 4: Analyze the OCT image to determine if it shows signs of these retinal diseases.**\n",
            "\n",
            "*   Look for the presence of hyperreflective lesions with a \"flower petal\" or \"leaf-like\" pattern, indicating CNV.\n",
            "*   Check for hyperreflective areas with cystoid spaces or a diffuse increase in retinal thickness, indicating DME.\n",
            "*   Examine the RPE layer for the presence of hyperreflective spots or patches, indicating early AMD.\n",
            "\n",
            "**Conclusion:**\n",
            "\n",
            "Based on the analysis of the OCT image, it appears to show signs of all three retinal diseases: choroidal neovascularization, diabetic macular edema, and early age-related macular degeneration.\n",
            "\n",
            "**Answer:** retinal diseases<|eot_id|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "run medgemma"
      ],
      "metadata": {
        "id": "A_02GXcxi4C9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub"
      ],
      "metadata": {
        "id": "WtF7LRqKi6hz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7167b358-c506-41dc-deb4-79b0deb4d353"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.32.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (1.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "9jcBBXRTi_c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ffa452d-cd24-4838-dbb6-76400aef9b69"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) Y\n",
            "Token is valid (permission: fineGrained).\n",
            "The token `medgamma` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `medgamma`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "content = \"How can we identify the features of choroidal neovascularization, Diabetic macular edema and early AMD in a Optical Coherence Tomography image of a person? Imagine you are an educator tasked with helping a student identify the features of an OCT image and whether or not the image shows signs of these retinal diseases as described by those features. As an educator, conclude your answer in - 'retinal diseases' or 'normal'. Describe your reasoning in steps.\"\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model_id = \"google/medgemma-4b-it\"\n",
        "\n",
        "model = AutoModelForImageTextToText.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "processor = AutoProcessor.from_pretrained(model_id)\n",
        "prediction = evaluate_image_medgemma(model, processor, image_path, content, device)\n",
        "print(prediction)"
      ],
      "metadata": {
        "id": "dLFLRWD7jD8Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1768282bd9e84bcd813adb70aa284f9a",
            "f844967135e44598921d115faaf96281",
            "1896a8d7344848da84229e0938d32676",
            "2d566e1746e0416bba5bc39887591bd1",
            "02d23a996cf74bb7b579afdaf540d0ea",
            "21dbab07a3404a118d0bfe2100942b67",
            "fa214ae07dbf4b82a776cc12f62e5675",
            "e3c6395f16e6495f9d296c6c4eec7f66",
            "4836742e8b7f495c9665701fafd58b22",
            "d77f12dcac054d11bf1a66d4eaaff06b",
            "762774a7d4364edca2b70106949d0568",
            "b449ac7f6b614485bf2ee01a7bf90b94",
            "ec53436fcc4f443da9a40e0240a8b84f",
            "2b85da1ed148451daef232092e579b5e",
            "803f57b59da5408ab06eec22af6c5584",
            "217d52c893be461d9da867f07f0c3463",
            "93eef834f829448388693bab28a90e48",
            "3bd81cbc2a3c4e09a3571dcd20ba7aa4",
            "122dcbf7ee604697a9488e42f3e8d95e",
            "02061feda70346e1922defdeeb74b77c",
            "58029513bf8945cb9995f48744e65d3a",
            "4053e5a1123845cf81b2638a7ae4f8b4",
            "18e4db60b66a401a8f69753ccce12391",
            "6906ba201639496b967a9bd7bf0b2b2d",
            "db1fe8cb51694f6d95330124192fc911",
            "db2f561ac6794f53a0dd58da17d80bfa",
            "baea04c89697491c92f912adaa39e5d6",
            "16c1dfb6e9c14c51ac91b4be4d97824f",
            "538967e9fbc642708c56ccb86401b64c",
            "d581272d247e4fc18a5f11721677d75b",
            "251ec5bd9c4b40f99fe7997d3303bd7d",
            "a0f46b42230d4400baee928d1dabd2d8",
            "a1ef300c9f3a4f029c8e9a7b72f63b05",
            "c2bff62185cb49edbc946a110f537e88",
            "6aa975e4e06b478f87859fc59be34f83",
            "735c2bb061d5455e82ecd31868e9d46a",
            "9dd1f4cf240b41a2be9bfbd2ff71e1bd",
            "34695206046d40d2b75a89d4cafa724c",
            "091c91ea6595449b999e1996510634b9",
            "464eb59cd78949dc913f54bd103fec69",
            "68ea8434292c477f80a1f97f56748ec2",
            "26e8443a7fdc4e2db25a28bc4036ad7f",
            "af0ac81cb1cd4059af2df41ef6403588",
            "d9c595d60d0c42658b8f0c7076b46789",
            "60164e2119c04f929c756adf0f80cd82",
            "0a056107ef6644c39345c669f61a64ae",
            "9fccb85dd678457bb3fb9f5f0831eae5",
            "88b9ddc567444dad8e314ab34a8f922d",
            "ee9ee934171c48458202f682f252e14c",
            "5751fb57a645488fab1d722cfa754b45",
            "ef8e037119624f379601c8422698994c",
            "abe4de329a4c4010afd4deaa6d565c6c",
            "2a3b4ae436f543fe95b1bdc9abd64954",
            "df14a756eeb8437f906f8b547110a4c8",
            "c675d45640cd436ab5430b1d962436c4",
            "0a5a6c10550845bcb056267f4dfeefaa",
            "1bc2159587384b4f8d2762e0314f1b75",
            "ba548868be5c485f92568f78f35b0767",
            "75b1e1acfed24809892bf1f0c551fa73",
            "22f2b94de3094907bcd585f7eaaabebc",
            "bbc249104a80471ba869303f8c6c4c04",
            "86e387d5df5d4789a11e2b4c6212eecd",
            "e8586f1cca7045a2b838ad941846812e",
            "293bc323b9ab44b4ba0ebc1af6b3c32e",
            "ab44e9c3a96747e183e80f793a37c772",
            "6589e48b8a5443b3b18798a443cf0503",
            "b897d92e55164882bef79e99fcc55ddd",
            "4ec125f8787e487789806e8147be36c6",
            "03646019c91a4a25914c20a105938ef6",
            "bfb0239f2156408d8da2292a3aba2cc2",
            "281a01eb4fe64fff84ceacbbe33e95d5",
            "55d3db981e6c4e83ba7bb6e248c06f69",
            "10374dc868764aea94fac0973b2b550f",
            "b85818775cc342ffa202f32cfd170f1a",
            "9c29af26ef174989a4601bcf440678fc",
            "63425453da7d47388ae253af6cd51a0f",
            "8eec0eaebbb142e88df9157422d30920",
            "5cf896ce836048dbac0bd4b1d0b7d72c",
            "d046e6faf0fb408487a53f3d6836b013",
            "2bf2048177964f02b95c4597023d1cb5",
            "4c213be187a5401a829150fc83bc4768",
            "eeb52185b4404678be5ff53db4e239a4",
            "dccc91fc51dd4dd9831b4899765b4a19",
            "525755bc1cb741c584b496c546a61564",
            "090696d1e19e4c78bf33c30145769da5",
            "1286492ebc554cd0a9d828a79e4c8a38",
            "f1e24ddee9f9450ebe85a224d6b86571",
            "9d0520a24d6249ebb154e030815eccda",
            "aa2bbbb6b9d8401b89592c31c4fe1f32",
            "c9907746d7134870a581ea0c34537e95",
            "298b9dddfc264f55b48bb7f60d5835ee",
            "a11199f4eb05471ca7a7dd556d8e41a5",
            "356a6b39c0eb4e73ad992f7180ac663e",
            "28067624283f4988b123aa6a6dca46a1",
            "84e18ff79c974d89b1ad5eaa60f3808a",
            "97c32506fdae46cdb6ccf522c1b9382b",
            "9a26253c22494641934b8abc52d66f42",
            "30e48b92681941a1808167c8b3e92639",
            "81535b6d63db47f7a4dc6b31822d9b0c",
            "7fb96c93afcc48e09e0ce7e53134e239",
            "acb5b4d6fa454262984db352548dfe1a",
            "ba96e757b8f74a718b32602e53d481de",
            "d560769cae0341c782b8706dc29f738c",
            "689dfd93d7214eb5bab807b638bb0c96",
            "167e27ac5c3745cb91d46ecec2a86745",
            "3bae4f4c41484e24acb80fcd4f818ad4",
            "706018ad9f8a49d5acb578d701dd7d5c",
            "9b8dca5fde404230b56b167dd3d946cc",
            "f601f163af2f4d14b1b738eaa130fb54",
            "b8bc28287c2341479038137b89978cd0",
            "e564011589ce402ba554cbaf334d87d7",
            "dfd2f2cf357845daad4b3175634b0ff2",
            "ce5aedbde2734d34b4f8b6c39307bcbd",
            "4ab2b07b78334369bac94df5a77bacc0",
            "81594116540b4db0901b2ceaccb826c4",
            "97c3e852fa4245b5a3575e9bc021c261",
            "e08504c21901427a864552440a08a82e",
            "88b671ab1c95461eb9808f87a9145d7d",
            "76e2dce950f5407d8a3a6302f54f8452",
            "6a0b1f39b6b24de09419c564a98166eb",
            "42456af771664b829c431843a065a65b",
            "91528daf38414748bb97edf573a87606",
            "18bb4682c2684f50b0355f02434e89b0",
            "194827a691b44095856213f73441a8b6",
            "5ecc684fe4d24354b49670038b869358",
            "cb40c41b0e3d400fbd8e0ee73371f2c6",
            "069eed6efe934312a83dcb50c34fbb05",
            "2e28af90d7ce442cb2511c17c75bd170",
            "aeda77e867b34059b2ed72d040a82ede",
            "229458e0e972458b9a0160c1d5f25c14",
            "9baee15795344b838d005b1249e797af",
            "20dff078bca24334a5e07e1b09c97ef9",
            "1e7034215cb1446c93e096160329132a",
            "7256c9a09d844f13afb3fa252885aafe",
            "48f951fdf30c4a55a593292633178909",
            "a20a22a8b2744c9895a01cf503fe632d",
            "ab4f9b39682f4807a868ec501bc147c6",
            "0e42cdc1817c457f95d62f33f9efb2ad",
            "c1c47b69e9874fe68929ea8672249f69",
            "b692bd84ff0c4a1f8ee74901614315fb",
            "82ceafe53f8f42ae8728bf2aa1ee8e80",
            "f538b90b3e8240a08f11db355e915b4c",
            "8318e9ab060745f7a6f54aa3ad5c4c94",
            "9b3eb3b3c94e453cab0046e28beed7ab",
            "5bd17980268c4fcb9bab46ac194cee27",
            "ff916003e9cf40c3aa33bc7702adfb1d",
            "21b2757d22484d95b1c3960f55304360",
            "1270ae57ed6844bb97eb7ce09a4f91c7",
            "4e144f3cf0c545a481237cac5cdb2252",
            "26bcdf5873ed465fbe2bd544e8c763f9",
            "22423393843b43e1ba3c3e81458f5dc0",
            "b0382ff0a53b495493a004e312e4d756",
            "ac439322d0c346b3819091d422468b32",
            "9ec6e31f3c37459bb8cf36856641355a",
            "0ccedf1c83ae4c17a3bec5ef701eecfe",
            "e1547e038cb243bfa482f0ca65ce00fe",
            "0800e1919e024f23abe3aa29ba40f975",
            "dabdae4e274147ddb5536e40f228c2ab",
            "d2dbd7f8462243fd849beade5ec37f02",
            "2d350b6679334bf8adaad4c12f79e062",
            "288e8703a0e54bfcab9ed0239038c7e7",
            "fde31baa134e4e67bb005e569c786ce9",
            "886a1aebbe1c4f04bceb41edfd4a5b2e",
            "29888e91dff749e2a72647999cb135aa",
            "2e2be16d6c9d4b36a4278b8f3b9f82ce"
          ]
        },
        "outputId": "55ec4049-c2cf-4417-dac8-695330403330"
      },
      "execution_count": 9,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1768282bd9e84bcd813adb70aa284f9a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/1.61k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b449ac7f6b614485bf2ee01a7bf90b94",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/90.6k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "18e4db60b66a401a8f69753ccce12391",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c2bff62185cb49edbc946a110f537e88",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/3.64G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "60164e2119c04f929c756adf0f80cd82",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0a5a6c10550845bcb056267f4dfeefaa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b897d92e55164882bef79e99fcc55ddd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/173 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5cf896ce836048dbac0bd4b1d0b7d72c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "processor_config.json:   0%|          | 0.00/70.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa2bbbb6b9d8401b89592c31c4fe1f32",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "chat_template.jinja:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7fb96c93afcc48e09e0ce7e53134e239",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e564011589ce402ba554cbaf334d87d7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.16M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "91528daf38414748bb97edf573a87606",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/4.69M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e7034215cb1446c93e096160329132a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9b3eb3b3c94e453cab0046e28beed7ab",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/35.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ccedf1c83ae4c17a3bec5ef701eecfe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:194: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.\n",
            "  warnings.warn(\n",
            "W0605 10:44:43.465000 5605 torch/_inductor/utils.py:1137] [0/0] Not enough SMs to use max_autotune_gemm mode\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, let's break down how to identify these retinal diseases on an OCT image. I'll guide you through the key features to look for, step-by-step.\n",
            "\n",
            "**1. Understanding the OCT Image:**\n",
            "\n",
            "*   **What is OCT?** OCT is a non-invasive imaging technique that provides high-resolution cross-sectional images of the retina. It uses light waves to create detailed images of the retinal layers.\n",
            "*   **Image Orientation:** The image shows a cross-sectional view of the retina. The top of the image represents the optic disc, and the bottom represents the macula. The horizontal axis represents the retinal thickness.\n",
            "\n",
            "**2. Identifying Choroidal Neovascularization (CNV):**\n",
            "\n",
            "*   **What is CNV?** CNV is the growth of abnormal blood vessels from the choroid (the vascular layer beneath the retina) into the retina. These vessels are fragile and prone to leakage, leading to fluid accumulation and vision loss.\n",
            "*   **Key Features to Look For:**\n",
            "    *   **Hyperreflectivity:** The abnormal blood vessels appear as bright, hyperreflective areas within the retina. This is because the blood vessels are filled with blood, which reflects light strongly.\n",
            "    *   **Location:** CNV typically occurs in the macula (the central part of the retina responsible for sharp, central vision).\n",
            "    *   **Shape:** The vessels can be irregular in shape and may have a \"beaded\" appearance.\n",
            "    *   **Presence of Fluid:** Look for fluid accumulation (retinochoroiditis) in the surrounding area of the CNV. This fluid appears as a hyporeflective (darker) area.\n",
            "*   **In the provided image:** There are no obvious hyperreflective areas or fluid accumulation that would suggest CNV.\n",
            "\n",
            "**3. Identifying Diabetic Macular Edema (DME):**\n",
            "\n",
            "*   **What is DME?** DME is a complication of diabetes that occurs when fluid leaks from damaged blood vessels in the retina, leading to swelling of the macula.\n",
            "*   **Key Features to Look For:**\n",
            "    *   **Hyperreflectivity:** The fluid accumulation appears as a bright, hyperreflective area within the retina. This is because the fluid is filled with water, which reflects light strongly.\n",
            "    *   **Location:** DME typically occurs in the macula.\n",
            "    *   **Shape:** The fluid accumulation can be irregular in shape.\n",
            "    *   **Presence of Retinal Thickening:** The surrounding retina may be thickened due to the fluid accumulation.\n",
            "*   **In the provided image:** There is no obvious hyperreflective area or retinal thickening that would suggest DME.\n",
            "\n",
            "**4. Identifying Early Age-Related Macular Degeneration (AMD):**\n",
            "\n",
            "*   **What is AMD?** AMD is a degenerative condition that affects the macula, leading to vision loss. There are two main types: dry AMD and wet AMD.\n",
            "*   **Key Features to Look For:**\n",
            "    *   **Dry AMD:**\n",
            "        *   **Atrophy:** The macula may appear atrophic (thinned) in the central area.\n",
            "        *   **Subretinal Fluid:** There may be a small amount of subretinal fluid (fluid under the retina).\n",
            "        *   **Pigmentary Changes:** There may be pigmentary changes in the retinal pigment epithelium (RPE).\n",
            "    *   **Wet AMD:**\n",
            "        *   **Subretinal Hemorrhage:** There may be a subretinal hemorrhage (bleeding under the retina).\n",
            "        *   **Neovascularization:** There may be neovascularization (new blood vessel growth) in the macula.\n",
            "*   **In the provided image:** There are no obvious signs of atrophy, subretinal fluid, pigmentary changes, or neovascularization that would suggest AMD.\n",
            "\n",
            "**Conclusion:**\n",
            "\n",
            "Based on the features observed in the OCT image, there are no clear signs of choroidal neovascularization, diabetic macular edema, or early age-related macular degeneration. Therefore, the image is most likely **normal**.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}
